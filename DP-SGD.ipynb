{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d74c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DP_SGD(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DP_SGD, self).__init__()\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 392)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(392, 10)\n",
    "        self.sm = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd7e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_PHYSICAL_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0ffb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "DATA_ROOT = '../mnist'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e3632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.5f}, δ = {DELTA})\"\n",
    "                )\n",
    "    return np.mean(top1_acc), epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d41576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "report = []\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "#for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "#    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "#    report.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a3d14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "e = []\n",
    "for i in report:\n",
    "    acc.append(i[0])\n",
    "    e.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc4a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_args = {'a1': 0.1, 'a3': 0.4, 'a4': 0.9, 'G_theta': 1, 'G_k': 2, 'E_lambda': 5, 'U_b': 2, 'U_a': 1, 'delta': 1e-05, 'overall_epsilon': 0.9479105959893149}\n",
    "args ={\n",
    "            \"a1\":gen_args['a1'],\n",
    "            \"a3\":gen_args['a3'],\n",
    "            \"a4\":gen_args['a4'],\n",
    "            \"lam\":gen_args['E_lambda'],\n",
    "            \"moment\":1,\n",
    "            \"theta\":gen_args['G_theta'],\n",
    "            'k':gen_args['G_k'],\n",
    "            'mu':0,\n",
    "            'sigma':0.5,\n",
    "            'a':gen_args['U_a'],\n",
    "            'b':gen_args['U_b'],\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcacc3",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5992722",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.608067274093628,\n",
    " 1.5012003183364868,\n",
    " 0.0010000000474974513,\n",
    " 2.7634339332580566,\n",
    " 2986173.5,\n",
    " 3732813.75,\n",
    " 1.0687086582183838,\n",
    " 0.0687086284160614,\n",
    " 1.100000023841858]\n",
    "args ={\n",
    "            \"a1\":1,\n",
    "            \"a3\":1,\n",
    "            \"a4\":1,\n",
    "            \"lam\":a[8],\n",
    "            \"moment\":1,\n",
    "            'k':a[0],\n",
    "            \"theta\":a[1],\n",
    "            'a':a[2],\n",
    "            'b':a[3],\n",
    "            'mu':a[4],\n",
    "            'sigma':a[5],\n",
    "            'u':a[6],\n",
    "            'l':a[7],\n",
    "            'epsilon':0.3,\n",
    "            'max_grad_norm': 5,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518056d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980cd0e75d474875ac098c8f6502cdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151  151\n",
      "\tTrain Epoch: 1 \tLoss: 2.303435 Acc@1: 10.613342 (ε = inf, δ = 1e-05)\n",
      "151  151\n",
      "\tTrain Epoch: 1 \tLoss: 2.303440 Acc@1: 10.514915 (ε = inf, δ = 1e-05)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m plrv_report_ep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 38\u001b[0m     acc, ep \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     plrv_report_acc\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     40\u001b[0m     plrv_report_ep\u001b[38;5;241m.\u001b[39mappend(ep)\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m top1_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m BatchMemoryManager(\n\u001b[1;32m     14\u001b[0m     data_loader\u001b[38;5;241m=\u001b[39mtrain_loader, \n\u001b[1;32m     15\u001b[0m     max_physical_batch_size\u001b[38;5;241m=\u001b[39mMAX_PHYSICAL_BATCH_SIZE, \n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m memory_safe_data_loader:\n\u001b[0;32m---> 19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmemory_safe_data_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "runs = []\n",
    "trun = []\n",
    "\n",
    "model = DP_SGD()\n",
    "#model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "    \n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier = 1,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=0.3,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=0.0001,\n",
    "        PLRV_args=args,\n",
    ")\n",
    "    \n",
    "plrv_report_acc = []\n",
    "plrv_report_ep = []\n",
    "\n",
    "for epoch in tqdm(range(2), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "    plrv_report_acc.append(acc)\n",
    "    plrv_report_ep.append(ep)\n",
    "    \n",
    "del model\n",
    "del optimizer\n",
    "#del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4b79a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from torch import nn\n",
    "runs = []\n",
    "trun = []\n",
    "\n",
    "model = DP_SGD()\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "    \n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp')\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        #noise_multiplier = 0.0051189550030173656,\n",
    "        epochs=2,\n",
    "        target_epsilon=0.3,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=1,\n",
    "        #PLRV_args=args,\n",
    ")\n",
    "    \n",
    "rdp_report_acc = []\n",
    "rdp_report_ep = []\n",
    "\n",
    "for epoch in tqdm(range(2), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "    rdp_report_acc.append(acc)\n",
    "    rdp_report_ep.append(ep)\n",
    "    \n",
    "\n",
    "del model\n",
    "del optimizer\n",
    "#del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "plt.plot(rdp_report_ep, rdp_report_acc, 'ro-', label=\"Gaussian\")\n",
    "plt.plot(plrv_report_ep, plrv_report_acc, 'bo-', label=\"PLRV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs epsilon (Gaussian at 0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "plt.plot(range(EPOCHS), rdp_report_acc, 'ro-', label=\"Gaussian\")\n",
    "plt.plot(range(EPOCHS), plrv_report_acc, 'bo-', label=\"PLRV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(EPOCHS))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs epsilon (Clipping = 50)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "plrv_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.3, 0.5, 1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_rdp = []\n",
    "for i in labels:\n",
    "    from opacus import PrivacyEngine\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = DP_GSD()\n",
    "    from opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            #noise_multiplier = 1,\n",
    "            epochs=EPOCHS,\n",
    "            target_epsilon=i,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=50,\n",
    "            #PLRV_args=args,\n",
    "    )\n",
    "\n",
    "    rdp_report_acc = []\n",
    "    rdp_report_ep = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        rdp_report_acc.append(acc)\n",
    "        rdp_report_ep.append(ep)\n",
    "\n",
    "\n",
    "    del model\n",
    "    del optimizer\n",
    "    #del results\n",
    "    torch.cuda.empty_cache()\n",
    "    reprt_rdp.append(test(model, test_loader, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [\"run 1\",\"run 2\",\"run 3\",\"run 4\",\"run 5\"]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(acc, e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.xticks(range(10))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Accuracy vs Epsilon\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ada8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "trun = []\n",
    "\n",
    "for i in [0.2, 0.3, 0.5, 1, 2]:\n",
    "    model = DP_GSD()\n",
    "\n",
    "    from .opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=i,\n",
    "        target_epsilon=1,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=2,\n",
    "    )\n",
    "    \n",
    "    report = []\n",
    "\n",
    "    for epoch in tqdm(range(i), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        report.append(results)\n",
    "    \n",
    "    runs.append(report)\n",
    "    trun.append(test(model, test_loader, device))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.2, 0.3, 0.5, 1, 2]\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Final Accuracy vs Epochs with Epsilon = 2\")\n",
    "plt.plot(x, y, 'bo-', label=\"Training Acc\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952add66",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del optimizer\n",
    "#del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d84d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "{'a1': 0.9, 'a3': 0.9, 'a4': 0.6, \n",
    " 'G_theta': 7.5, 'G_k': 1, 'E_lambda': 0.1, \n",
    " 'U_b': 2, 'U_a': 1, 'delta': 1e-05, \n",
    " 'overall_epsilon': 0.9321347520012611, \n",
    " 'usefulness': 0.9930061301242415}\n",
    "args ={\n",
    "            \"a1\":0.7,\n",
    "            \"a3\":0.9,\n",
    "            \"a4\":0.6,\n",
    "            \"lam\":0.1,\n",
    "            \"moment\":1,\n",
    "            \"theta\":7.5,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.5,\n",
    "            'a':1,\n",
    "            'b':2,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1000), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import opacus.accountants.analysis.rdp_plrv as rdp_accounting\n",
    "from opacus.accountants.analysis import rdp as gaussian_analysis\n",
    "\n",
    "def compute_privacy_lmo_alpha(lmo, alpha):\n",
    "    MGF1_1 = ((1-lmo['a1']*(alpha-1)*lmo['G_theta'])**(-lmo['G_k']))  # Gamma\n",
    "    MGF1_3 = (lmo['E_lambda']/(lmo['E_lambda']-lmo['a3']*(alpha-1)))  # Exponential\n",
    "    MGF1_4 = ((np.exp(lmo['a4']*(alpha-1)*lmo['U_b'])-np.exp(lmo['a4']*(alpha-1)*lmo['U_a']))/(lmo['a4']*(alpha-1)*(lmo['U_b']-lmo['U_a'])))  # Uniform\n",
    "    MGF1 = MGF1_1 * MGF1_3 * MGF1_4\n",
    "    \n",
    "    MGF2_1 = ((1-lmo['a1']*(-alpha)*lmo['G_theta'])**(-lmo['G_k']))  # Gamma\n",
    "    MGF2_3 = (lmo['E_lambda']/(lmo['E_lambda']-lmo['a3']*(-alpha)))  # Exponential\n",
    "    MGF2_4 = ((np.exp(lmo['a4']*(-alpha)*lmo['U_b'])-np.exp(lmo['a4']*(-alpha)*lmo['U_a']))/(lmo['a4']*(-alpha)*(lmo['U_b']-lmo['U_a'])))  # Uniform\n",
    "    MGF2 = MGF2_1 * MGF2_3 * MGF2_4\n",
    "    \n",
    "    rdp_lmo_ = (1/(alpha-1)) * np.log((alpha*MGF1+(alpha-1)*MGF2)/(2*alpha-1))\n",
    "    return rdp_lmo_\n",
    "\n",
    "\n",
    "def compute_privacy_lmo(lmo, steps=118, Clip = 1):\n",
    "    \n",
    "    if lmo['a1']*(min(DEFAULT_ALPHAS)-1)<1/lmo['G_theta'] and lmo['a1']*(-max(DEFAULT_ALPHAS))<1/lmo['G_theta'] and lmo['a3']*(min(DEFAULT_ALPHAS)-1)<lmo['E_lambda'] and lmo['a3']*(-max(DEFAULT_ALPHAS))<lmo['E_lambda']:\n",
    "        # print(\"Parameters meet the requirements.\")\n",
    "        pass\n",
    "    else:\n",
    "        # print(\"Parameters cannot meet the requirements.\")\n",
    "        return []\n",
    "\n",
    "    rdp_lmo = np.zeros_like(DEFAULT_ALPHAS, dtype=float)\n",
    "    for alpha in DEFAULT_ALPHAS:\n",
    "        try:\n",
    "            args ={\n",
    "            \"a1\":lmo['a1'],\n",
    "            \"a3\":lmo['a3'],\n",
    "            \"a4\":lmo['a4'],\n",
    "            \"lam\":lmo['E_lambda'],\n",
    "            \"moment\":1,\n",
    "            \"theta\":lmo['G_theta'],\n",
    "            'k':lmo['G_k'],\n",
    "            'mu':0,\n",
    "            'sigma':0.5,\n",
    "            'a':lmo['U_a'],\n",
    "            'b':lmo['U_b'],\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }\n",
    "            rdp_lmo_ = rdp_accounting._compute_rdp(args, order=alpha)\n",
    "            #print(f\"{rdp_lmo_}  {compute_privacy_lmo_alpha(lmo, alpha=alpha)}\")\n",
    "            if rdp_lmo_>0:\n",
    "                rdp_lmo[int(alpha-2)] += rdp_lmo_\n",
    "            else:\n",
    "                rdp_lmo[int(alpha-2)] += np.inf\n",
    "        except:\n",
    "        #    print(\"issue\")\n",
    "            rdp_lmo[int(alpha-2)] += np.inf\n",
    "    \n",
    "    #try:\n",
    "    rens = []\n",
    "    for i in range(len(DEFAULT_ALPHAS)):\n",
    "        overall_epsilon, opt_order = rdp_accounting.get_privacy_spent(orders=DEFAULT_ALPHAS[i], rdp=rdp_lmo[i], delta=lmo['delta'])\n",
    "        sigma = np.sqrt((2*np.log(1.25/lmo['delta'])*float(clip)**2)/float(overall_epsilon)**2)\n",
    "        #print(sigma)\n",
    "        overall_epsilon = (gaussian_analysis._compute_rdp(0.0085, sigma, opt_order))\n",
    "        rens.append(overall_epsilon)\n",
    "    overall_epsilon, opt_order = rdp_accounting.get_privacy_spent(orders=DEFAULT_ALPHAS, rdp=np.array(rens)*steps, delta=lmo['delta'])\n",
    "        \n",
    "    #except:\n",
    "        #raise ArithmeticError\n",
    "    \n",
    "    return overall_epsilon, opt_order, rdp_lmo\n",
    "\n",
    "\n",
    "def compute_usefulness_lmo(lmo, lmo_gamma=0.9):\n",
    "    # usefulness = 1 - M1(-a1*gamma) * M3(-a3*gamma) * M4(-a4*gamma)\n",
    "    MGF1 = ((1-(-lmo['a1']*lmo_gamma)*lmo['G_theta'])**(-lmo['G_k']))  # Gamma\n",
    "    MGF3 = (lmo['E_lambda']/(lmo['E_lambda']-(-lmo['a3']*lmo_gamma)))  # Exponential\n",
    "    MGF4 = ((np.exp((-lmo['a4']*lmo_gamma)*lmo['U_b'])-np.exp((-lmo['a4']*lmo_gamma)*lmo['U_a']))/((-lmo['a4']*lmo_gamma)*(lmo['U_b']-lmo['U_a'])))  # Uniform\n",
    "    usefulness = 1 - MGF1 * MGF3 * MGF4\n",
    "    \n",
    "    return usefulness, lmo_gamma\n",
    "\n",
    "def take_Si(SS):\n",
    "    # Function to fetch a set of parameters at one time. \n",
    "    times=1\n",
    "    for item in SS:\n",
    "        times=times*len(SS[item])\n",
    "\n",
    "    Si={}\n",
    "    move=True\n",
    "    one_round=len(SS)-1\n",
    "    pos=[int(i) for i in np.zeros(len(SS))]\n",
    "\n",
    "    cnt=0\n",
    "    for _ in range(times):\n",
    "        for idx, ss in enumerate(SS):\n",
    "            try:\n",
    "                if ss=='G_theta_k':\n",
    "                    Si[\"G_theta\"]=SS[ss][pos[idx]][0]\n",
    "                    Si[\"G_k\"]=SS[ss][pos[idx]][1]\n",
    "                elif ss==\"U_b_a\":\n",
    "                    Si[\"U_b\"]=SS[ss][pos[idx]][0]\n",
    "                    Si[\"U_a\"]=SS[ss][pos[idx]][1]\n",
    "                else:\n",
    "                    Si[ss]=SS[ss][pos[idx]]\n",
    "            except:\n",
    "                pos[idx]=0\n",
    "                pos[int(idx+1)]=pos[int(idx+1)]+1\n",
    "                \n",
    "                if ss=='G_theta_k':\n",
    "                    Si[\"G_theta\"]=SS[ss][pos[idx]][0]\n",
    "                    Si[\"G_k\"]=SS[ss][pos[idx]][1]\n",
    "                elif ss==\"U_b_a\":\n",
    "                    Si[\"U_b\"]=SS[ss][pos[idx]][0]\n",
    "                    Si[\"U_a\"]=SS[ss][pos[idx]][1]\n",
    "                else:\n",
    "                    Si[ss]=SS[ss][pos[idx]]\n",
    "                \n",
    "            if move:\n",
    "                pos[idx]+=1 if pos[idx]<len(SS[ss]) else pos[idx]\n",
    "                move=False\n",
    "            if cnt<one_round:\n",
    "                cnt=cnt+1\n",
    "                continue\n",
    "            else:\n",
    "                yield Si\n",
    "                Si={}\n",
    "                move=True\n",
    "                cnt=0\n",
    "\n",
    "\n",
    "def search_epsilon(SS, epsilon_threshold, demo_cnt=118):\n",
    "    # The searched condition is epsilon_threshold.\n",
    "    cnt = 0\n",
    "    searched_parameters = {}\n",
    "    searched_parameters[\"overall_epsilon\"] = 0\n",
    "    for lmo in take_Si(SS):\n",
    "        privacy_lmo = compute_privacy_lmo(lmo)\n",
    "        if privacy_lmo==[]:\n",
    "            continue\n",
    "        else:\n",
    "            overall_epsilon, opt_order, rdp_lmo = privacy_lmo\n",
    "            if overall_epsilon < epsilon_threshold and np.isreal(rdp_lmo[int(opt_order-2)]):\n",
    "                if overall_epsilon > searched_parameters['overall_epsilon']:\n",
    "                    searched_parameters = lmo\n",
    "                    searched_parameters[\"overall_epsilon\"] = overall_epsilon\n",
    "        \n",
    "        cnt = cnt + 1\n",
    "        if demo_cnt == cnt:\n",
    "            break\n",
    "    \n",
    "    return searched_parameters\n",
    "\n",
    "\n",
    "def search_usefulness(SS, epsilon_threshold, lmo_gamma=0.9, demo_cnt=1000):\n",
    "    # The searched condition is epsilon_threshold and usefulness.\n",
    "    cnt = 0\n",
    "    searched_parameters = {}\n",
    "    searched_parameters[\"overall_epsilon\"] = 0\n",
    "    searched_parameters[\"usefulness\"] = 0\n",
    "    for lmo in take_Si(SS):\n",
    "        privacy_lmo = compute_privacy_lmo(lmo)\n",
    "        usefulness, _ = compute_usefulness_lmo(lmo, lmo_gamma=lmo_gamma)\n",
    "        if privacy_lmo==[]:\n",
    "            continue\n",
    "        else:\n",
    "            overall_epsilon, opt_order, rdp_lmo = privacy_lmo\n",
    "            if overall_epsilon < epsilon_threshold and np.isreal(rdp_lmo[int(opt_order-2)]):\n",
    "                if usefulness > searched_parameters[\"usefulness\"]:\n",
    "                    searched_parameters = lmo\n",
    "                    searched_parameters[\"overall_epsilon\"] = overall_epsilon\n",
    "                    searched_parameters[\"usefulness\"] = usefulness\n",
    "        \n",
    "        cnt = cnt + 1\n",
    "        if demo_cnt == cnt:\n",
    "            break\n",
    "    \n",
    "    return searched_parameters\n",
    "\n",
    "\n",
    "def save_epsilon_usefulness(SS, epsilon_threshold, lmo_gamma=0.9, demo_cnt=1000):\n",
    "    # Just save epsilon and usefulness of all parameters.\n",
    "    cnt = 0\n",
    "    for sdx, lmo in enumerate(take_Si(SS)):\n",
    "        if sdx==0:\n",
    "            columns = list(lmo.keys())\n",
    "            columns.extend([\"overall_epsilon\", \"usefulness\"])\n",
    "            df=pd.DataFrame([], columns=columns)\n",
    "        privacy_lmo = compute_privacy_lmo(lmo)\n",
    "        usefulness, _ = compute_usefulness_lmo(lmo, lmo_gamma=lmo_gamma)\n",
    "        if privacy_lmo==[]:\n",
    "            continue\n",
    "        else:\n",
    "            overall_epsilon, opt_order, rdp_lmo = privacy_lmo\n",
    "            if overall_epsilon < epsilon_threshold and np.isreal(rdp_lmo[int(opt_order-2)]):\n",
    "                added_parameters = list(lmo.values())\n",
    "                added_parameters.extend([overall_epsilon, usefulness])\n",
    "                df.loc[len(df.index)] = added_parameters\n",
    "        \n",
    "        cnt = cnt + 1\n",
    "        if demo_cnt == cnt:\n",
    "            break\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "S = {\n",
    "    \"a1\": np.linspace(0.1, 0.9, 9),\n",
    "    \"a3\": np.linspace(0.1, 0.9, 9),\n",
    "    \"a4\": np.linspace(0.1, 0.9, 9),\n",
    "    \"G_theta_k\": [(1,2), (2,2), (3,2), (5,1), (9,0.5), (7.5,1), (0.5,1)],  # k>0; theta>0; t<1/theta\n",
    "    \"E_lambda\": [0.1, 0.5, 1, 5],  # E_lambda>0; t<E_lambda;\n",
    "    \"U_b_a\": [(1,0), (2,1)],  # b>a; when t=0: MGF=1;\n",
    "    \"delta\": [1e-5],\n",
    "}\n",
    "epsilon_threshold = 1\n",
    "lmo_gamma = 0.9\n",
    "DEFAULT_ALPHAS = range(1,60)\n",
    "demo_cnt = False  # The options could be {False, \"any numbers\"(3000, ...)}; Choosing False will go through all the paramters.\n",
    "save_df = False\n",
    "\n",
    "searched_parameters_epsilon = search_epsilon(S, epsilon_threshold, demo_cnt=demo_cnt)\n",
    "print(f\"When considering maximum the epsilon below {epsilon_threshold}, we found the parameters: {searched_parameters_epsilon}.\")\n",
    "\n",
    "searched_parameters_usefulness = search_usefulness(S, epsilon_threshold, lmo_gamma=lmo_gamma, demo_cnt=demo_cnt)\n",
    "print(f\"When considering maximum the usefulness below epsilon {epsilon_threshold}, we found the parameters: {searched_parameters_usefulness}.\")\n",
    "\n",
    "## another choice: saving the epsilon and the usefulness of all parameters and choosing parameters offline.\n",
    "df = save_epsilon_usefulness(S, epsilon_threshold, lmo_gamma=lmo_gamma, demo_cnt=demo_cnt)\n",
    "if save_df:\n",
    "    df.to_csv(f\"parameters_gamma{lmo_gamma}.csv\")\n",
    "else:\n",
    "    print(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94812723",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_accounting._compute_rdp(args, order=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06f11a",
   "metadata": {},
   "source": [
    "# Make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model = 'ResNet50'\n",
    "opt = 'RMSPropo'\n",
    "clip = '100'\n",
    "delta = '1e-5'\n",
    "epochs = 10\n",
    "l_r = 1e-2\n",
    "batch_s = 512\n",
    "max_physical_batch_s = 128\n",
    "ds = 'MNIST'\n",
    "params = [\n",
    "    {'a1': 0.9, 'a3': 0.7000000000000001, 'a4': 0.7000000000000001, 'G_theta': 0.5, 'G_k': 1, 'E_lambda': 0.5, 'U_b': 2, 'U_a': 1, 'delta': 1e-05, 'overall_epsilon': 0.29997436726316473},\n",
    "    {'a1': 0.1, 'a3': 0.1, 'a4': 0.9, 'G_theta': 5, 'G_k': 1, 'E_lambda': 5, 'U_b': 2, 'U_a': 1, 'delta': 1e-05, 'overall_epsilon': 0.49975823560281035},\n",
    "    {'a1': 0.4, 'a3': 0.1, 'a4': 0.9, 'G_theta': 0.5, 'G_k': 1, 'E_lambda': 5, 'U_b': 2, 'U_a': 1, 'delta': 1e-05, 'overall_epsilon': 0.5086451322342973},\n",
    "]\n",
    "results_plrv = [\n",
    "    {\n",
    "        'loss': 0.282926,\n",
    "        'accuracy': 94.256089,\n",
    "        'final epsilon': 0.10289,\n",
    "        'Time per Epoch': '83.33',\n",
    "        'Total Training Time': '13:53',\n",
    "        #'accountant': 'PLRV',\n",
    "    },\n",
    "    {\n",
    "        'loss': 2.129738,\n",
    "        'accuracy': 76.164982, \n",
    "        'final epsilon': 0.10290,\n",
    "        'Time per Epoch': None,\n",
    "        'Total Training Time': None,\n",
    "        #'accountant': 'PLRV',\n",
    "    }, \n",
    "    {\n",
    "        'loss': 1.325533,\n",
    "        'accuracy': 79.775391, \n",
    "        'final epsilon': 0.10290,\n",
    "        'Time per Epoch': None,\n",
    "        'Total Training Time': None,\n",
    "        #'accountant': 'PLRV',\n",
    "    },\n",
    "]\n",
    "\n",
    "results_gauss = [\n",
    "    {\n",
    "        'loss': 4.442263,\n",
    "        'accuracy': 52.423598,\n",
    "        'final epsilon': 0.29219,\n",
    "        'Time per Epoch': '45.66',\n",
    "        'Total Training Time': '7:36',\n",
    "        #'accountant': 'gaussian RDP',\n",
    "    },\n",
    "    {\n",
    "        'loss': 4.254029,\n",
    "        'accuracy': 62.690717, \n",
    "        'final epsilon': 0.48728,\n",
    "        'Time per Epoch': None,\n",
    "        'Total Training Time': None,\n",
    "        #'accountant': 'gaussian RDP',\n",
    "    }, \n",
    "    {\n",
    "        'loss': 3.240867,\n",
    "        'accuracy': 65.336052,\n",
    "        'final epsilon': 0.49695,\n",
    "        'Time per Epoch': None,\n",
    "        'Total Training Time': None,\n",
    "        #'accountant': 'gaussian RDP',\n",
    "    }, \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(params)\n",
    "df2 = pd.DataFrame.from_dict(results_plrv)\n",
    "df3 = pd.DataFrame.from_dict(results_gauss)\n",
    "result = pd.concat([df2, df3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfa0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Model'] = model\n",
    "result['Optimizer'] = opt\n",
    "result['Clipping Threshold'] = clip\n",
    "result['Epochs'] = epochs\n",
    "result['Learning Rate'] = l_r\n",
    "result['Batch Size'] = batch_s\n",
    "result['Max Physical Batch Size'] = max_physical_batch_s\n",
    "result['Dataset'] = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe2abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
