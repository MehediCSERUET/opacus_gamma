{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d74c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DP_GSD(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DP_GSD, self).__init__()\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 392)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(392, 10)\n",
    "        self.sm = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd7e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_PHYSICAL_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0ffb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "DATA_ROOT = '../mnist'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(num_classes=10)\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "ModuleValidator.validate(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9fe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Nextcloud2/RAstuff/opacus/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "#model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "#    module=model,\n",
    "#    optimizer=optimizer,\n",
    "#    data_loader=train_loader,\n",
    "#    epochs=EPOCHS,\n",
    "#    target_epsilon=EPSILON,\n",
    "#    target_delta=DELTA,\n",
    "#    max_grad_norm=MAX_GRAD_NORM,\n",
    "#)\n",
    "\n",
    "#print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e3632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                )\n",
    "    return acc, epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d41576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "report = []\n",
    "\n",
    "#for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "#    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "#    report.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3d14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "e = []\n",
    "for i in report:\n",
    "    acc.append(i[0])\n",
    "    e.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc4a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "            \"a1\":0.1,\n",
    "            \"a3\":0.1,\n",
    "            \"a4\":0.1,\n",
    "            \"lam\":5,\n",
    "            \"moment\":1,\n",
    "            \"theta\":0.05,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.1,\n",
    "            'a':0,\n",
    "            'b':1,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518056d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "runs = []\n",
    "trun = []\n",
    "\n",
    "model = DP_GSD()\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "    \n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier = 1,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=0.5,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=1,\n",
    "        PLRV_args=args,\n",
    ")\n",
    "    \n",
    "plrv_report_acc = []\n",
    "plrv_report_ep = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "    plrv_report_acc.append(acc)\n",
    "    plrv_report_ep.append(ep)\n",
    "    \n",
    "del model\n",
    "del optimizer\n",
    "del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77b4b79a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Nextcloud2/RAstuff/opacus/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/tmp/ipykernel_365362/3959651094.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.sm(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Epoch: 1 \tLoss: 2.247524 Acc@1: 53.328867 (ε = 0.11, δ = 1e-05)\n",
      "\tTrain Epoch: 1 \tLoss: 2.170614 Acc@1: 61.743939 (ε = 0.12, δ = 1e-05)\n",
      "\tTrain Epoch: 2 \tLoss: 1.913602 Acc@1: 72.595604 (ε = 0.13, δ = 1e-05)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_365362/1527144760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_365362/1470961225.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtop1_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are trying to call the hook of a dead Module!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Nextcloud2/RAstuff/opacus/opacus/grad_sample/grad_sample_module.py\u001b[0m in \u001b[0;36mcapture_backprops_hook\u001b[0;34m(self, module, _forward_input, forward_output, loss_reduction, batch_first)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mgrad_sampler_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft_compute_per_sample_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mgrad_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_sampler_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrad_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             create_or_accumulate_grad_sample(\n",
      "\u001b[0;32m~/Nextcloud2/RAstuff/opacus/opacus/grad_sample/linear.py\u001b[0m in \u001b[0;36mcompute_linear_grad_sample\u001b[0;34m(layer, activations, backprops)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n...i,n...j->nij\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "runs = []\n",
    "trun = []\n",
    "\n",
    "model = DP_GSD()\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "    \n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp')\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        #noise_multiplier = 1,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=0.5,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=1,\n",
    "        #PLRV_args=args,\n",
    ")\n",
    "    \n",
    "rdp_report_acc = []\n",
    "rdp_report_ep = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "    rdp_report_acc.append(acc)\n",
    "    rdp_report_ep.append(ep)\n",
    "    \n",
    "\n",
    "del model\n",
    "del optimizer\n",
    "del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "plt.plot(rdp_report_ep, rdp_report_acc, 'ro-', label=\"Gaussian\")\n",
    "plt.plot(plrv_report_ep, plrv_report_acc, 'bo-', label=\"PLRV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs epsilon (Gaussian at 0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e6ab0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   \n",
    "plt.plot(range(10), rdp_report_acc, 'ro-', label=\"Gaussian\")\n",
    "plt.plot(range(10), plrv_report_acc, 'bo-', label=\"PLRV\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs epsilon (Gaussian at 0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.2, 0.3, 0.5, 1, 2]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(range(10), e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [\"run 1\",\"run 2\",\"run 3\",\"run 4\",\"run 5\"]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(acc, e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.xticks(range(10))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Accuracy vs Epsilon\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ada8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "trun = []\n",
    "\n",
    "for i in [0.2, 0.3, 0.5, 1, 2]:\n",
    "    model = DP_GSD()\n",
    "\n",
    "    from .opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=i,\n",
    "        target_epsilon=1,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=2,\n",
    "    )\n",
    "    \n",
    "    report = []\n",
    "\n",
    "    for epoch in tqdm(range(i), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        report.append(results)\n",
    "    \n",
    "    runs.append(report)\n",
    "    trun.append(test(model, test_loader, device))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.2, 0.3, 0.5, 1, 2]\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Final Accuracy vs Epochs with Epsilon = 2\")\n",
    "plt.plot(x, y, 'bo-', label=\"Training Acc\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952add66",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1000), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d84d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "            \"a1\":0.1,\n",
    "            \"a3\":0.1,\n",
    "            \"a4\":0.1,\n",
    "            \"lam\":5,\n",
    "            \"moment\":1,\n",
    "            \"theta\":0.5,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.5,\n",
    "            'a':1,\n",
    "            'b':2,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1000), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
