{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88c1809f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gamma, uniform, truncnorm, norm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import itertools\n",
    "from opacus.accountants.analysis.rdp import compute_rdp, get_privacy_spent\n",
    "import math\n",
    "\n",
    "\n",
    "delta_values = [1e-5, 1e-10]\n",
    "epsilons = np.array([0.5, 0.7, 0.9])  # Range of epsilon\n",
    "T_value = (512/60000)  # Fixed T value\n",
    "sensitivity_values = np.arange(0.1, 1.1, 0.3)  # Sensitivity ranging from 0.1 to 5 with an increment of 0.1\n",
    "\n",
    "# Define reasonable ranges for the other parameters\n",
    "k_values = np.array([0.1, 0.3, 0.5, 0.7])#, 0.5, 0.7, 0.9,1,2])\n",
    "theta_values = np.array([0.3, 0.5, 0.7, 0.9])#,2,3,5,7.5,9])\n",
    "a_values = np.arange(0, 1.1, 0.3)\n",
    "b_values = np.arange(1, 1.1, 0.3)  # Ensure b > a\n",
    "mu_values = np.arange(0, 1.1, 0.3)\n",
    "sigma_values = np.arange(0.1, 1.1, 0.3)\n",
    "l_values = np.arange(0.1, 1.1, 0.3)\n",
    "u_values = np.arange(1, 1.1, 0.3)\n",
    "#t_values = np.arange(0.01, 0.51, 0.15)\n",
    "lamda_values=np.array([1, 2, 3, 5])\n",
    "\n",
    "\n",
    "# PDF functions based on the given distributions\n",
    "def gamma_pdf(k, theta, x):\n",
    "    return gamma.pdf(x, k, scale=theta)\n",
    "\n",
    "def uniform_pdf(a, b, x):\n",
    "    return uniform.pdf(x, loc=a, scale=b - a)\n",
    "\n",
    "def truncated_normal_pdf(mu, sigma, l, u, x):\n",
    "    return norm.pdf(x, mu, sigma) / (norm.cdf(u, mu, sigma) - norm.cdf(l, mu, sigma))\n",
    "\n",
    "# Objective function\n",
    "def objective_function(k, theta, a, b, mu, sigma, l, u):\n",
    "    gamma_expect = k * theta\n",
    "    uniform_expect = (a + b) / 2\n",
    "    normal_expect = mu + sigma * (norm.pdf((l - mu) / sigma) - norm.pdf((u - mu) / sigma)) / (norm.cdf((u - mu) / sigma) - norm.cdf((l - mu) / sigma))\n",
    "    return gamma_expect + uniform_expect + normal_expect\n",
    "\n",
    "# MGF functions\n",
    "def mgf_gamma(k, theta, t):\n",
    "    if t * theta >= 1:\n",
    "        return np.nan  # Prevent undefined behavior\n",
    "    return (1 - t * theta) ** (-k)\n",
    "\n",
    "def mgf_uniform(a, b, t):\n",
    "    if t == 0:\n",
    "        return 1  # Special case for t = 0\n",
    "    return (np.exp(b * t) - np.exp(a * t)) / (t * (b - a))\n",
    "\n",
    "def mgf_truncated_normal(mu, sigma, l, u, t):\n",
    "    alpha = (l - mu) / sigma\n",
    "    beta = (u - mu) / sigma\n",
    "    num = truncnorm.cdf(beta - sigma * t, alpha, beta, loc=mu, scale=sigma) - truncnorm.cdf(alpha - sigma * t, alpha, beta, loc=mu, scale=sigma)\n",
    "    den = truncnorm.cdf(beta, alpha, beta, loc=mu, scale=sigma) - truncnorm.cdf(alpha, alpha, beta, loc=mu, scale=sigma)\n",
    "    return np.exp((mu * t + 0.5 * sigma ** 2 * t ** 2)/2) * num / den\n",
    "\n",
    "def MGF_PLRV(k, theta, a, b, mu, sigma, l, u, T_value, t):\n",
    "    return np.prod([mgf_gamma(k, theta, t), mgf_uniform(a, b, t), mgf_truncated_normal(mu, sigma, l, u, t)]) ** T_value\n",
    "    #return mgf_truncated_normal(mu, sigma, l, u, t) ** T_value\n",
    "\n",
    "# Grid search for one epsilon value\n",
    "def grid_search_for_epsilon(lamda_values, epsilon, T_value, sensitivity_values, delta_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values):\n",
    "    best_params = None\n",
    "    best_value = -np.inf\n",
    "    min_lemma1 = float('inf')\n",
    "    \n",
    "    for lamda, sensitivity, k, theta, a, b, mu, sigma, l, u, delta in itertools.product(\n",
    "            lamda_values, sensitivity_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values, delta_values):\n",
    "        \n",
    "        # Apply constraints\n",
    "        if b > a and u > l and sigma > 0 and theta > 0:\n",
    "            obj_value = objective_function(k, theta, a, b, mu, sigma, l, u)\n",
    "            \n",
    "            # Compute the terms in the numerator\n",
    "            term1 = (lamda + 1) * MGF_PLRV(k, theta, a, b, mu, sigma, l, u, T_value, lamda * sensitivity)\n",
    "            term2 = lamda * MGF_PLRV(k, theta, a, b, mu, sigma, l, u, T_value, -(lamda + 1) * sensitivity)\n",
    "            numerator = term1 + term2\n",
    "\n",
    "            # Compute the denominator\n",
    "            denominator = (2 * lamda + 1) * np.exp(lamda * (epsilon/T_value))\n",
    "\n",
    "            # Compute delta for the current lambda\n",
    "            lemma1 = numerator / denominator\n",
    "\n",
    "            L = obj_value - (lemma1)\n",
    "            \n",
    "            if lemma1 <= delta:\n",
    "                L = -np.inf\n",
    "            \n",
    "            test_ep = (lemma1/(lamda*sensitivity)+math.log(1/delta)/(lamda*sensitivity))\n",
    "            # Keep track of the minimum delta\n",
    "            if L > best_value:\n",
    "                best_value = L\n",
    "                best_params = {'epsilon': epsilon, 'T': T_value, 'sensitivity': sensitivity, 'k': k, 'theta': theta, 'a': a, 'b': b, 'mu': mu, 'sigma': sigma, 'l': l, 'u': u, 'lambda': lamda}\n",
    "    return best_params, best_value\n",
    "\n",
    "\n",
    "# Split epsilon values evenly across threads\n",
    "def split_epsilons_across_threads(epsilons, num_threads):\n",
    "    split_size = len(epsilons) // num_threads\n",
    "    epsilon_splits = [epsilons[i:i + split_size] for i in range(0, len(epsilons), split_size)]\n",
    "    return epsilon_splits\n",
    "\n",
    "# Parallel grid search, assigning unique epsilon subsets to each thread\n",
    "def grid_search_concurrent(lamda_values, epsilon_splits, T_value, sensitivity_values, delta_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values):\n",
    "    print(\"Starting grid search...\")\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=len(epsilon_splits)) as executor:\n",
    "        futures = []\n",
    "        for epsilon_subset in epsilon_splits:\n",
    "            futures.append(executor.submit(grid_search_for_epsilon_subset,lamda_values, epsilon_subset, T_value, sensitivity_values, delta_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values))\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            results.extend(future.result())\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Grid search over an epsilon subset\n",
    "def grid_search_for_epsilon_subset(lamda_values, epsilon_subset, T_value, sensitivity_values, delta_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values):\n",
    "    subset_results = []\n",
    "    for epsilon in epsilon_subset:\n",
    "        best_params, best_value = grid_search_for_epsilon(lamda_values, epsilon, T_value, sensitivity_values, delta_values, k_values, theta_values, a_values, b_values, mu_values, sigma_values, l_values, u_values)\n",
    "        subset_results.append({'epsilon': epsilon, 'best_params': best_params, 'best_value': best_value})\n",
    "    return subset_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631edfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949909/766864719.py:60: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return np.exp((mu * t + 0.5 * sigma ** 2 * t ** 2)/2) * num / den\n",
      "/tmp/ipykernel_1949909/766864719.py:60: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp((mu * t + 0.5 * sigma ** 2 * t ** 2)/2) * num / den\n",
      "/tmp/ipykernel_1949909/766864719.py:60: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return np.exp((mu * t + 0.5 * sigma ** 2 * t ** 2)/2) * num / den\n",
      "/tmp/ipykernel_1949909/766864719.py:60: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.exp((mu * t + 0.5 * sigma ** 2 * t ** 2)/2) * num / den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12646.4996062405\n",
      "11986.413827135591\n",
      "24805.340627073074\n",
      "8947.344801608599\n",
      "8817.75744934734\n",
      "9133.839810813546\n",
      "9337.065669707483\n",
      "8311.289824296216\n",
      "-70800.97800908303\n",
      "16200.77341009917\n",
      "18558.49906022567\n",
      "18291.40482582426\n",
      "17861.280736090313\n",
      "29993.92248971256\n",
      "20738.437111015093\n",
      "22492.77309611305\n",
      "13690.876149211388\n",
      "-1376.0499623429394\n",
      "12645.53423576033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949909/766864719.py:41: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  normal_expect = mu + sigma * (norm.pdf((l - mu) / sigma) - norm.pdf((u - mu) / sigma)) / (norm.cdf((u - mu) / sigma) - norm.cdf((l - mu) / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7975.6936844206475\n",
      "-14811.597021719403\n",
      "17443.973710653772\n",
      "17584.450184952526\n",
      "18667.29911945318\n",
      "6736.677585684333\n",
      "121.5685612890553\n",
      "-6094.524705496537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949909/766864719.py:63: RuntimeWarning: overflow encountered in scalar power\n",
      "  return np.prod([mgf_gamma(k, theta, t), mgf_uniform(a, b, t), mgf_truncated_normal(mu, sigma, l, u, t)]) ** T_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16175.472076213602\n",
      "13718.399793200655\n",
      "-20817.1826154842\n",
      "18148.234255142423\n",
      "14442.046329777377\n",
      "17308.061227023314\n",
      "53157.670911916124\n",
      "20086.734665869004\n",
      "19740.040004086728\n",
      "8805.232835615145\n",
      "-3166.0711835593074\n",
      "14102.204209499876\n",
      "13464.152342690519\n",
      "13270.602796537469\n",
      "13188.347334356495\n",
      "13151.693803044322\n",
      "13139.331369701928\n",
      "26495.75274082093\n",
      "14859.618412546835\n",
      "14921.29955573302\n",
      "17192.50304981283\n",
      "234.99566510034845\n",
      "21466.680077304314\n",
      "15100.504257430062\n",
      "16353.294821567773\n",
      "24243.188289779922\n",
      "-49995.841108129316\n",
      "15752.365683249867\n",
      "12293.350305496358\n",
      "812.0224184934774\n",
      "-14665.172344221437\n",
      "20453.037477288522\n",
      "-31736.577146007923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1949909/766864719.py:41: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  normal_expect = mu + sigma * (norm.pdf((l - mu) / sigma) - norm.pdf((u - mu) / sigma)) / (norm.cdf((u - mu) / sigma) - norm.cdf((l - mu) / sigma))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-60512.670706142184\n",
      "9549.001158291512\n",
      "-7221.741390638768\n",
      "-9619.143203276635\n",
      "869.3139028901559\n",
      "40888.67796784874\n",
      "-25836.613133840947\n",
      "14718.461873375394\n",
      "14167.025190478951\n",
      "34524.60442789138\n",
      "28626.1670367711\n",
      "61772.06148507046\n",
      "17629.747416150385\n",
      "-8918.139755711078\n",
      "11409.710383035625\n",
      "-17145.614557564273\n",
      "-19480.17517938484\n",
      "-26987.138520402674\n",
      "15881.100632009133\n",
      "-11886.771994195622\n",
      "14538.128828602794\n",
      "26523.37037611542\n",
      "26189.99424250663\n",
      "9297.482476878562\n",
      "3367.566179802433\n",
      "-11563.917675167964\n",
      "-10617.3228227984\n",
      "-26936.67745062018\n",
      "18064.771003326125\n",
      "17695.733827876622\n",
      "13330.064876253165\n",
      "18226.985105904154\n",
      "22962.87538051736\n",
      "14344.33951176531\n",
      "-9466.98306132175\n",
      "-11367.57374808511\n",
      "-11584.227788075197\n",
      "-11470.20239115689\n",
      "-12453.43722753972\n",
      "6549.265859600489\n",
      "19216.975931238758\n",
      "18094.257085623867\n",
      "24500.83310874371\n",
      "15025.65277044422\n",
      "9062.443609784003\n",
      "38047.18280862381\n",
      "10745.763100361019\n",
      "10212.164714829876\n",
      "10133.873308933487\n",
      "10184.745659255677\n",
      "10314.931187917684\n",
      "10550.762113991\n",
      "11226.119493926064\n",
      "64542.80266300507\n",
      "-5291.452653038063\n",
      "-15751.547567793667\n",
      "14423.542076694886\n",
      "11102.860072539635\n",
      "-25582.76568880518\n",
      "-15931.817123603863\n",
      "-24513.318561464395\n",
      "-6482.622613599729\n",
      "4146.891626370448\n",
      "19078.941464225572\n",
      "-308.8221415279357\n",
      "-4128.402408175194\n",
      "-5164.056186636451\n",
      "-7860.508971620094\n",
      "19870.104521620342\n",
      "46054.76426412228\n",
      "22327.038049679297\n",
      "17967.83477831731\n",
      "-5250.006322100357\n",
      "57292.01060842826\n",
      "15831.25492618498\n",
      "14446.659987371733\n",
      "12454.404804938851\n",
      "9929.539169445758\n",
      "16519.608477137226\n",
      "19459.78947934854\n",
      "6442.169392558577\n",
      "-21710.753064670676\n",
      "-29903.325756132486\n",
      "19047.49847614165\n",
      "19770.449447535168\n",
      "9967.70331737407\n",
      "11538.663281313948\n",
      "31437.551272313456\n",
      "19511.842785973255\n",
      "15795.77993535539\n",
      "9257.644700731487\n",
      "8766.248582322558\n",
      "8564.871288758994\n",
      "19006.403470581172\n",
      "14423.736264707219\n",
      "14748.045183563629\n",
      "4735.228855773694\n",
      "59622.65916973902\n",
      "41936.4884507834\n",
      "28472.81831409363\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "import math\n",
    "listofvalues = []\n",
    "count =0\n",
    "sm = 0\n",
    "divisor = .0001\n",
    "while (len(listofvalues) < 50):\n",
    "    T_value = 118\n",
    "    #lamda = randrange(10)\n",
    "    epsilon = 3\n",
    "    delta = 1e-5\n",
    "    sensitivity = 1\n",
    "    k = randrange(1000)/1000+0.000001\n",
    "    theta = randrange(1000)/1000 \n",
    "    a = randrange(1000)/1000\n",
    "    b = randrange(1000)/1000\n",
    "    mu = randrange(1000)/1000\n",
    "    sigma = randrange(1000)/1000\n",
    "    l = randrange(1000)/1000\n",
    "    u  = l+randrange(1000)/1000\n",
    "    best_params = None\n",
    "    best_value = -np.inf\n",
    "    min_lemma1 = float('inf')\n",
    "        \n",
    "    if b > a and u > l and sigma > 0 and theta > 0:\n",
    "        \n",
    "        obj_value = objective_function(k, theta, a, b, mu, sigma, l, u)\n",
    "        \n",
    "        \n",
    "        for i in range(1,100):\n",
    "            lamda = i\n",
    "\n",
    "            # Compute the terms in the numerator\n",
    "            try:\n",
    "                term1 = (lamda + 1) * MGF_PLRV(k, theta, a, b, mu, sigma, l, u, T_value, lamda * sensitivity)\n",
    "                term2 = lamda * MGF_PLRV(k, theta, a, b, mu, sigma, l, u, T_value, -(lamda + 1) * sensitivity)\n",
    "                term1_maf = (lamda + 1) * mgf_truncated_normal(mu, sigma, l, u, lamda * sensitivity)\n",
    "                term2_maf = lamda * mgf_truncated_normal(mu, sigma, l, u, -(lamda + 1) * sensitivity)\n",
    "            except: \n",
    "                #print((lamda + 1) * mgf_truncated_normal(mu, sigma, l, u, lamda * sensitivity))\n",
    "                continue\n",
    "            numerator = term1 + term2\n",
    "            numerator_maf = term1_maf + term2_maf\n",
    "\n",
    "            # Compute the denominator\n",
    "            denominator = (2 * lamda + 1) * np.exp(lamda * (epsilon))\n",
    "            denominator_maf = (2 * lamda + 1)\n",
    "\n",
    "            # Compute delta for the current lambda\n",
    "            lemma1 = numerator / denominator\n",
    "            \n",
    "            try:\n",
    "                maf = math.log(numerator / denominator)\n",
    "            except:\n",
    "                #print(\"Except2\")\n",
    "                continue\n",
    "                \n",
    "            test_ep = (math.log(1/delta)+maf)/lamda\n",
    "            L = obj_value# - (lemma1)\n",
    "            if not math.isnan(test_ep) and maf < np.inf:\n",
    "                print(test_ep*T_value)\n",
    "        \n",
    "            if (not math.isnan(test_ep)) and test_ep*T_value <= epsilon and test_ep*T_value >= epsilon-(epsilon/10): #and test_ep <= epsilon/T_value:\n",
    "                listofvalues.append([lamda, sensitivity, k, theta, a, b, mu, sigma, l, u])\n",
    "                print(listofvalues)\n",
    "                print(f\"{mgf_truncated_normal(mu, sigma, l, u, lamda)}\")\n",
    "\n",
    "            else:\n",
    "                L = -np.inf\n",
    "\n",
    "                # Keep track of the minimum delta\n",
    "            if L > best_value:\n",
    "                best_value = L\n",
    "                best_params = {'epsilon': epsilon, 'T': T_value, 'sensitivity': sensitivity, 'k': k, 'theta': theta, 'a': a, 'b': b, 'mu': mu, 'sigma': sigma, 'l': l, 'u': u, 'lambda': lamda}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e768b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda, sensitivity, k, theta, a, b, mu, sigma, l, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "listofvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127d843",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamda, sensitivity, k, theta, a, b, mu, sigma, l, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mgf_truncated_normal(2.22, 0.45, 3.06, 3.77, 25*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f513bda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer(DPOptimizer):\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5062656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "            \"a1\":0.1,\n",
    "            \"a3\":0.1,\n",
    "            \"a4\":0.1,\n",
    "            \"lam\":5,\n",
    "            \"moment\":1,\n",
    "            \"theta\":0.05,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.1,\n",
    "            'a':0,\n",
    "            'b':1,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer(optim.RMSprop(model.parameters(), lr=LR))\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f46c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollector:\n",
    "  def __init__(self):\n",
    "    import pandas as pd\n",
    "    self.data = []\n",
    "    \n",
    "  def entry(self, args, accuracy, epochs, learning_rate, epsilon, delta, clipping_threshold, \n",
    "            sampling_rate, batch_size, training_time, **kwargs\n",
    "           ):\n",
    "    df1 = pd.DataFrame.from_dict(args)\n",
    "    df2 = pd.DataFrame.from_dict(kwargs)\n",
    "    d = {'Accuracy':accuracy, 'Epochs':epochs, 'Learning Rate':learning_rate, \n",
    "         'Epsilon':epsilon, 'Delta':delta, 'Clipping Threshold':clipping_threshold, \n",
    "         'Sampling Rate':sampling_rate, 'Batch Size': batch_size, 'Training Time':training_time\n",
    "        }\n",
    "    df3 = pd.DataFrame.from_dict(d)\n",
    "    result = pd.concat([df1, df2, df3], axis=1)\n",
    "    \n",
    "  def save_table(self, filename ='table.csv'):\n",
    "    pd.DataFrame.from_dict(self.data).to_csv(filename)\n",
    "    \n",
    "  def head(self, count=5):\n",
    "    pd.DataFrame.from_dict(self.data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52ad688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict({'a':'b', 'args':args})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9320120",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dc \u001b[38;5;241m=\u001b[39m data_collector()\n\u001b[0;32m----> 2\u001b[0m dc\u001b[38;5;241m.\u001b[39mentry(\u001b[43margs\u001b[49m, accuracy, epochs, learning_rate, epsilon, delta, clipping_threshold, \n\u001b[1;32m      3\u001b[0m             sampling_rate, batch_size, training_time, fiiz\u001b[38;5;241m=\u001b[39mbuzz)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "dc = data_collector()\n",
    "dc.entry(args, accuracy, epochs, learning_rate, epsilon, delta, clipping_threshold, \n",
    "            sampling_rate, batch_size, training_time, fizz=buzz)\n",
    "dc.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6ccaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
