{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d74c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DP_GSD(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DP_GSD, self).__init__()\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 392)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(392, 10)\n",
    "        self.sm = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd7e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_PHYSICAL_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0ffb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "DATA_ROOT = '../mnist'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DP_GSD()\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "ModuleValidator.validate(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9fe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Documents/NextCloud/RAstuff/opacus/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "#model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "#    module=model,\n",
    "#    optimizer=optimizer,\n",
    "#    data_loader=train_loader,\n",
    "#    epochs=EPOCHS,\n",
    "#    target_epsilon=EPSILON,\n",
    "#    target_delta=DELTA,\n",
    "#    max_grad_norm=MAX_GRAD_NORM,\n",
    "#)\n",
    "\n",
    "#print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd68aa",
   "metadata": {},
   "source": [
    "## Everything from here is basically the same as from the opacus tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e3632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                )\n",
    "    return acc, epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d41576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "report = []\n",
    "\n",
    "#for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "#    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "#    report.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3d14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "e = []\n",
    "for i in report:\n",
    "    acc.append(i[0])\n",
    "    e.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518056d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d62a37eff22b461aaaef4ca9387f5018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/knil/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 1 \tLoss: 2.302160 Acc@1: 9.185558 (ε = 14.74, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Documents/NextCloud/RAstuff/opacus/opacus/accountants/analysis/rdp_plrv.py:123: UserWarning: Optimal order is the smallest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 1 \tLoss: 2.302178 Acc@1: 9.328038 (ε = 27.52, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 2 \tLoss: 2.302220 Acc@1: 9.000377 (ε = 48.81, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 2 \tLoss: 2.302160 Acc@1: 9.293720 (ε = 61.87, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 3 \tLoss: 2.302314 Acc@1: 8.785202 (ε = 82.03, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 3 \tLoss: 2.302274 Acc@1: 9.065707 (ε = 95.09, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 4 \tLoss: 2.302207 Acc@1: 9.787472 (ε = 115.25, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 4 \tLoss: 2.302178 Acc@1: 9.683930 (ε = 128.03, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 5 \tLoss: 2.302227 Acc@1: 9.083937 (ε = 148.75, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 5 \tLoss: 2.302216 Acc@1: 9.178710 (ε = 161.53, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 6 \tLoss: 2.302238 Acc@1: 9.317914 (ε = 182.25, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 6 \tLoss: 2.302230 Acc@1: 9.387696 (ε = 195.03, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 7 \tLoss: 2.302180 Acc@1: 9.378413 (ε = 215.76, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 7 \tLoss: 2.302191 Acc@1: 9.413566 (ε = 228.82, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 8 \tLoss: 2.302222 Acc@1: 9.214317 (ε = 249.54, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 8 \tLoss: 2.302230 Acc@1: 9.116414 (ε = 262.60, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 9 \tLoss: 2.302153 Acc@1: 9.422900 (ε = 282.76, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 9 \tLoss: 2.302182 Acc@1: 9.357704 (ε = 295.54, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 10 \tLoss: 2.302189 Acc@1: 9.124897 (ε = 316.26, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 10 \tLoss: 2.302196 Acc@1: 9.276012 (ε = 329.32, δ = 1e-05)\n",
      "\tTest set:Loss: 2.302145 Acc: 9.330193 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0835efd22864ec39d0978a4afe08388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 1 \tLoss: 2.302594 Acc@1: 10.056065 (ε = 15.03, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 1 \tLoss: 2.302500 Acc@1: 10.069608 (ε = 27.52, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 2 \tLoss: 2.302501 Acc@1: 10.362690 (ε = 47.96, δ = 1e-05)\n",
      "1.6036319455376271\n",
      "0.5160567759552755\n",
      "10.082386831509238\n",
      "\tTrain Epoch: 2 \tLoss: 2.302505 Acc@1: 10.230869 (ε = 60.74, δ = 1e-05)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m report \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     report\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     36\u001b[0m runs\u001b[38;5;241m.\u001b[39mappend(report)\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m top1_acc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m BatchMemoryManager(\n\u001b[1;32m     14\u001b[0m     data_loader\u001b[38;5;241m=\u001b[39mtrain_loader, \n\u001b[1;32m     15\u001b[0m     max_physical_batch_size\u001b[38;5;241m=\u001b[39mMAX_PHYSICAL_BATCH_SIZE, \n\u001b[1;32m     16\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m memory_safe_data_loader:\n\u001b[0;32m---> 19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmemory_safe_data_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/datasets/mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/transforms/functional.py:139\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_tensor\u001b[39m(pic: Union[PILImage, np\u001b[38;5;241m.\u001b[39mndarray]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a ``PIL Image`` or ``numpy.ndarray`` to tensor.\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m    This function does not support torchscript.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_tracing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    140\u001b[0m         _log_api_usage_once(to_tensor)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/jit/_trace.py:1133\u001b[0m, in \u001b[0;36mis_tracing\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1128\u001b[0m         torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m old_module_map\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[0;32m-> 1133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_tracing\u001b[39m():\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a boolean value.\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[1;32m   1136\u001b[0m \u001b[38;5;124;03m    Returns ``True`` in tracing (if a function is called during the\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;124;03m    tracing of code with ``torch.jit.trace``) and ``False`` otherwise.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_scripting():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "runs = []\n",
    "trun = []\n",
    "for i in [0.2, 0.3, 0.5, 1, 2]:\n",
    "    model = DP_GSD()\n",
    "\n",
    "    from opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier = 1,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=1,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=0.1,\n",
    "    )\n",
    "    \n",
    "    report = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        report.append(results)\n",
    "    \n",
    "    runs.append(report)\n",
    "    trun.append(test(model, test_loader, device))\n",
    "    del model\n",
    "    del optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.2, 0.3, 0.5, 1, 2]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(range(10), e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.2, 0.3, 0.5, 1, 2]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(range(10), e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [\"run 1\",\"run 2\",\"run 3\",\"run 4\",\"run 5\"]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(acc, e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.xticks(range(10))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Accuracy vs Epsilon\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ada8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "trun = []\n",
    "\n",
    "for i in [0.2, 0.3, 0.5, 1, 2]:\n",
    "    model = DP_GSD()\n",
    "\n",
    "    from .opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=i,\n",
    "        target_epsilon=1,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=2,\n",
    "    )\n",
    "    \n",
    "    report = []\n",
    "\n",
    "    for epoch in tqdm(range(i), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        report.append(results)\n",
    "    \n",
    "    runs.append(report)\n",
    "    trun.append(test(model, test_loader, device))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.2, 0.3, 0.5, 1, 2]\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Final Accuracy vs Epochs with Epsilon = 2\")\n",
    "plt.plot(x, y, 'bo-', label=\"Training Acc\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
