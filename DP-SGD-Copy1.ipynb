{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d74c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DP_GSD(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DP_GSD, self).__init__()\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.l1 = nn.Linear(784, 392)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(392, 10)\n",
    "        self.sm = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cd7e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-5\n",
    "EPOCHS = 10\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "MAX_PHYSICAL_BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e0ffb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/knil/.local/lib/python3.12/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "DATA_ROOT = '../mnist'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DP_GSD()\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "ModuleValidator.validate(model, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a9fe910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Documents/NextCloud/RAstuff/opacus/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "#model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "#    module=model,\n",
    "#    optimizer=optimizer,\n",
    "#    data_loader=train_loader,\n",
    "#    epochs=EPOCHS,\n",
    "#    target_epsilon=EPSILON,\n",
    "#    target_delta=DELTA,\n",
    "#    max_grad_norm=MAX_GRAD_NORM,\n",
    "#)\n",
    "\n",
    "#print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd68aa",
   "metadata": {},
   "source": [
    "## Everything from here is basically the same as from the opacus tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e3632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n",
    "                )\n",
    "    return acc, epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d41576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "report = []\n",
    "\n",
    "#for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "#    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "#    report.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3d14ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "e = []\n",
    "for i in report:\n",
    "    acc.append(i[0])\n",
    "    e.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "518056d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36395630b374feb9bbb5622ca0a00f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/knil/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Epoch: 1 \tLoss: 2.299899 Acc@1: 12.522495 (ε = 2.51, δ = 1e-05)\n",
      "\tTrain Epoch: 1 \tLoss: 2.299756 Acc@1: 12.185771 (ε = 3.74, δ = 1e-05)\n",
      "\tTrain Epoch: 2 \tLoss: 2.299233 Acc@1: 12.990965 (ε = 5.26, δ = 1e-05)\n",
      "\tTrain Epoch: 2 \tLoss: 2.299437 Acc@1: 11.874527 (ε = 6.07, δ = 1e-05)\n",
      "\tTrain Epoch: 3 \tLoss: 2.299820 Acc@1: 10.156465 (ε = 7.21, δ = 1e-05)\n",
      "\tTrain Epoch: 3 \tLoss: 2.299443 Acc@1: 10.165536 (ε = 7.88, δ = 1e-05)\n",
      "\tTrain Epoch: 4 \tLoss: 2.299215 Acc@1: 10.174192 (ε = 8.91, δ = 1e-05)\n",
      "\tTrain Epoch: 4 \tLoss: 2.299094 Acc@1: 10.448313 (ε = 9.50, δ = 1e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x748535b52e80>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/knil/.local/lib/python3.12/site-packages/tqdm/std.py\", line 1147, in __del__\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m report \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 32\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     report\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     35\u001b[0m runs\u001b[38;5;241m.\u001b[39mappend(report)\n",
      "Cell \u001b[0;32mIn[6], line 38\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m top1_acc\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 38\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     42\u001b[0m     epsilon \u001b[38;5;241m=\u001b[39m privacy_engine\u001b[38;5;241m.\u001b[39mget_epsilon(DELTA)\n",
      "File \u001b[0;32m~/Documents/NextCloud/RAstuff/opacus/opacus/optimizers/optimizer.py:553\u001b[0m, in \u001b[0;36mDPOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m    552\u001b[0m         closure()\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/NextCloud/RAstuff/opacus/opacus/optimizers/optimizer.py:538\u001b[0m, in \u001b[0;36mDPOptimizer.pre_step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_and_accumulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_skip_next_step():\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_last_step_skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NextCloud/RAstuff/opacus/opacus/optimizers/LMODPOptimizer.py:78\u001b[0m, in \u001b[0;36mPLRVDPOptimizer.clip_and_accumulate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m     per_sample_clip_factor \u001b[38;5;241m=\u001b[39m zeros(\n\u001b[1;32m     74\u001b[0m         (\u001b[38;5;241m0\u001b[39m,), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     per_param_norms \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 78\u001b[0m         \u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_samples\n\u001b[1;32m     79\u001b[0m     ]\n\u001b[1;32m     80\u001b[0m     per_sample_norms \u001b[38;5;241m=\u001b[39m stack(per_param_norms, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;241m1\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m     per_sample_clip_factor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm \u001b[38;5;241m/\u001b[39m (per_sample_norms \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m     83\u001b[0m     )\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/_tensor.py:765\u001b[0m, in \u001b[0;36mTensor.norm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    763\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mnorm, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, p\u001b[38;5;241m=\u001b[39mp, dim\u001b[38;5;241m=\u001b[39mdim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    764\u001b[0m     )\n\u001b[0;32m--> 765\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/functional.py:1631\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1629\u001b[0m _p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m p\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mvector_norm(\u001b[38;5;28minput\u001b[39m, _p, _dim, keepdim, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "runs = []\n",
    "trun = []\n",
    "\n",
    "model = DP_GSD()\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n",
    "    \n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "    \n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        noise_multiplier = 1,\n",
    "        epochs=EPOCHS,\n",
    "        target_epsilon=0.3,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=1,\n",
    ")\n",
    "    \n",
    "report = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "    report.append(results)\n",
    "    \n",
    "runs.append(report)\n",
    "trun.append(test(model, test_loader, device))\n",
    "del model\n",
    "del optimizer\n",
    "del results\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.2, 0.3, 0.5, 1, 2]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(range(10), e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [0.2, 0.3, 0.5, 1, 2]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(range(10), e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xticks(range(10))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "labels = [\"run 1\",\"run 2\",\"run 3\",\"run 4\",\"run 5\"]\n",
    "for j in range(len(runs)):\n",
    "    acc = []\n",
    "    e = []\n",
    "    for i in runs[j]:\n",
    "        acc.append(i[0])\n",
    "        e.append(i[1])\n",
    "    \n",
    "    plt.plot(acc, e, label=labels[j])\n",
    "    \n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.xticks(range(10))\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Training Accuracy per Epoch for different values of Maximum Epsilon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Final Accuracy vs Epsilon\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ada8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = []\n",
    "trun = []\n",
    "\n",
    "for i in [0.2, 0.3, 0.5, 1, 2]:\n",
    "    model = DP_GSD()\n",
    "\n",
    "    from .opacus.validators import ModuleValidator\n",
    "\n",
    "    model = ModuleValidator.fix(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine()\n",
    "    \n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "        module=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "        epochs=i,\n",
    "        target_epsilon=1,\n",
    "        target_delta=DELTA,\n",
    "        max_grad_norm=2,\n",
    "    )\n",
    "    \n",
    "    report = []\n",
    "\n",
    "    for epoch in tqdm(range(i), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        report.append(results)\n",
    "    \n",
    "    runs.append(report)\n",
    "    trun.append(test(model, test_loader, device))\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.2, 0.3, 0.5, 1, 2]\n",
    "y=[]\n",
    "for i in runs:\n",
    "    y.append(i[-1][0])\n",
    "\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "#plt.title(\"Final Accuracy vs Epochs with Epsilon = 2\")\n",
    "plt.plot(x, y, 'bo-', label=\"Training Acc\")\n",
    "plt.plot(x, trun, 'ro-', label=\"Testing Acc\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "            \"a1\":0.1,\n",
    "            \"a3\":0.1,\n",
    "            \"a4\":0.1,\n",
    "            \"lam\":5,\n",
    "            \"moment\":1,\n",
    "            \"theta\":0.05,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.1,\n",
    "            'a':0,\n",
    "            'b':1,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952add66",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fb5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1000), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d84d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opacus.optimizers.optimizer import _check_processed_flag, _mark_as_processed, DPOptimizer\n",
    "from torch.distributions.laplace import Laplace\n",
    "from torch.distributions.gamma import Gamma\n",
    "from torch.distributions.normal import Normal\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch import stack, zeros, einsum\n",
    "from opacus.optimizers.utils import params\n",
    "from torch import nn\n",
    "from torch.optim import Optimizer\n",
    "from scipy.stats import truncnorm, expon\n",
    "\n",
    "class PLRVDPOptimizer():\n",
    "    \"\"\"\n",
    "    Implementation of PLRV first noise mechanism.\n",
    "    \"\"\"\n",
    "        \n",
    "    def make_noise(self, args):\n",
    "        self.args = args\n",
    "        self.k = self.args['k']\n",
    "        self.theta = self.args['theta']\n",
    "        self.mu = self.args['mu']\n",
    "        self.sigma = self.args['sigma']\n",
    "        self.a = self.args['a']\n",
    "        self.b = self.args['b']\n",
    "        self.l = self.args['l']\n",
    "        self.u = self.args['u']\n",
    "        self.clip = self.args['max_grad_norm']\n",
    "        self.lam = self.args['lam']\n",
    "        \n",
    "        a_transformed, b_transformed = (self.l - self.mu) / self.sigma, (self.u - self.mu) / self.sigma\n",
    "        \n",
    "        self.gamma = Gamma(\n",
    "          concentration = self.k, rate = self.theta\n",
    "          )\n",
    "        self.normal= truncnorm(\n",
    "          a_transformed, b_transformed, loc=self.mu, scale=self.sigma\n",
    "          )\n",
    "        self.uniform = Uniform(\n",
    "          low = self.a, high = self.b\n",
    "          )\n",
    "        self.expon = expon(loc=0, scale = 1/self.lam)\n",
    "    \n",
    "    \n",
    "    def add_noise(self):\n",
    "          \n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.summed_grad)\n",
    "            \n",
    "            laplace = self.get_laplace()\n",
    "            noise = laplace.sample(p.summed_grad.shape).to(p.summed_grad.device)\n",
    "            p.grad = p.summed_grad + noise\n",
    "\n",
    "            _mark_as_processed(p.summed_grad)\n",
    "            \n",
    "    def get_linear_combination(self):\n",
    "        gam = self.gamma.sample()\n",
    "        uni = self.uniform.sample()\n",
    "        t_norm = self.normal.rvs(size=1)[0]  \n",
    "        exp = self.expon.rvs(size=1)[0]\n",
    "        return 1/(self.args['a1']*gam+self.args['a3']*exp+self.args['a4']*uni)\n",
    "        \n",
    "    def get_laplace(self):\n",
    "        return Laplace(loc=0, scale=self.get_linear_combination())\n",
    "        \n",
    "    def clip_and_accumulate(self):\n",
    "        \"\"\"\n",
    "        Performs gradient clipping.\n",
    "        Stores clipped and aggregated gradients into `p.summed_grad```\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.grad_samples[0]) == 0:\n",
    "            # Empty batch\n",
    "            per_sample_clip_factor = zeros(\n",
    "                (0,), device=self.grad_samples[0].device\n",
    "            )\n",
    "        else:\n",
    "            per_param_norms = [\n",
    "                g.reshape(len(g), -1).norm(1, dim=-1) for g in self.grad_samples\n",
    "            ]\n",
    "            per_sample_norms = stack(per_param_norms, dim=1).norm(1, dim=1)\n",
    "            per_sample_clip_factor = (\n",
    "                self.max_grad_norm / (per_sample_norms + 1e-6)\n",
    "            ).clamp(max=1.0)\n",
    "\n",
    "        for p in self.params:\n",
    "            _check_processed_flag(p.grad_sample)\n",
    "            grad_sample = self._get_flat_grad_sample(p)\n",
    "            grad = einsum(\"i,i...\", per_sample_clip_factor, grad_sample)\n",
    "\n",
    "            if p.summed_grad is not None:\n",
    "                p.summed_grad += grad\n",
    "            else:\n",
    "                p.summed_grad = grad\n",
    "\n",
    "            _mark_as_processed(p.grad_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={\n",
    "            \"a1\":0.1,\n",
    "            \"a3\":0.1,\n",
    "            \"a4\":0.1,\n",
    "            \"lam\":5,\n",
    "            \"moment\":1,\n",
    "            \"theta\":0.5,\n",
    "            'k':1,\n",
    "            'mu':0,\n",
    "            'sigma':0.5,\n",
    "            'a':1,\n",
    "            'b':2,\n",
    "            'u':1,\n",
    "            'l':0.1,\n",
    "            'epsilon':1,\n",
    "            'max_grad_norm': 1,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651aa0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = PLRVDPOptimizer()\n",
    "noise.make_noise(args)\n",
    "laplace = noise.get_laplace()\n",
    "laplace.sample((1,1000)).tolist()[0]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "samples = []\n",
    "for i in range(1000):\n",
    "    laplace = noise.get_laplace()\n",
    "    samples.append(laplace.sample().tolist())\n",
    "    \n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c402dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1000), samples)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
